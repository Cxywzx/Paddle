# 如何写一个Layer

这个文档是一个概念性的文档，描述在重构后用户如何写一个Layer。

## 基本目标

用户只需要写Layer的计算信息，而不需要写配置解析器，也不修改写Protobuf的内容。就可以完成Layer的书写。

## 实现方式

### 总体概览

* 在注册Layer的时候，不只注册Layer的C++类型，同时注册Layer的信息，这个信息使用Protobuf来表示。
* 使用一个静态函数生成，Layer信息的Protobuf。


### LayerDef/LayerOutputDef Protobuf.

Paddle将Layer在C++端注册信息，声明成Protobuf。一个Layer的信息主体分为两个部分:

* Layer本身的信息
	* 包括这个Layer支持什么样类型的输入
	* 这个Layer的参数，bias有哪些可以设置的属性
	* 这个Layer本身有哪些可以设置的属性
* Layer输出什么类型
	* 这个Layer在某一种输入下，的输出类型是什么样子的。
	* 由于Paddle的一个Layer可以接受和产生不同类型的输入和输出，Layer的输出类型(例如size)是和输入有关系的。所以这个信息是解析配置文件过程中运行时调用生成的。

```protobuf
enum DataType {
  DENSE=0,
  SPARSE_INT=1,
  SPARSE=2,
  INT=3,
}

enum AttributeType {
  STRING=0,
  INT=1,
  FLOAT=2,
  DOUBLE=3,
  ...
}

message Attribute {
  oneof {
    string s_value = 1;
    int    i_value = 2;
    float  f_value = 3;
    ...
  }
}

message AttributeDef {
  required string name = 1;  // supported attribute name.
  required AttributeType type = 2;  // supported type.
  required string description = 3; // Attribute description & comments.
  
  optional Attribute default_value = 4; // default value.
  optional Attribute max_value = 5;    // max value.
  optional Attribute min_value = 6;   // min value.
}

// Argument Define the Supported InputTypes.
message ArgumentDef {
   	// Supported Input Type.
   	// The data type of input/output.
   	repeated DataType data_type = 1; 
   	// 0 means it is not a sequence. 1 means a plain sequence. 2 means a nested sequence.  One layer could support many sequence type.
   	repeated uint32 seq_nested_level = 2;
    	
   	// In paddle, some layer can handle variable length input.
   	// If some input is repeatable, it means there are one or many inputs as the same input type.
   	required bool repeatable = 3;
    	
	// In Paddle, a layer could return many outputs. Each output contains a different name.
   	required string name = 4;
   	
   	// Comments
  	required string description = 5;
}

message LayerDef {
    required string type = 1;  // Layer type, such as 'fc', 'conv'
    required string description = 2;  // Layer description & comments.
    
    
    repeated ArgumentDef inputs = 3;
    
    
    message ParameterDef {
        repeated AttributeDef attributes = 1;  // Parameter Attributes Definition.
    }
    
    // Each input of Paddle Layer should contain zero or one parameter.
    // so parameter_attr.size() == inputs.size()
    repeated ParameterDef parameter_attr = 5;
    
    // Set the bias attribute, If this layer support bias.
    optional ParameterDef bias_attr = 6;
    
    // The Layer Attributes.
    repeated AttributeDef layer_attr = 7;
}

// Define the layer's output types by given input types.
message LayerOutputDef {
	// Output name, Each Paddle Layer could have multiple outputs.
	optional string name = 1;
	
	// Output type
	required DataType type = 2;
	required uint32 size = 3;
	required uint32 seq_nested_level = 4;
	
}
```

### C++ 端暴露LayerDef/LayerOutputDef Protobuf.

基本想法:

* 对于每一种类型的Layer，Paddle根据Layer的名字约定两个全局函数的名字。例如，对于FC Layer，全局函数的名字是 `__get_fc_layer_definition__` 和 `__get_fc_layer_output_definition__`。 这两个全局函数通过`REGISTER_LAYER`自动生成。
* 对于每个Layer实现的时候，实现两个静态(`static`)函数，分别实现这两个函数。
* 对于获得LayerOutputDef的函数，其还有一个作用就是在运行时设置ParameterSize，动态添加辅助输入等等。

举例来说，例如对于FCLayer，可能的实现为:

```C++

class FCLayer :public Layer {
public:
  void init() { ... }
  void forward() { ... }
  void backward() { ... }
  
  static void getLayerDefinition(LayerDef& def) {
    LayerDefinition::supportSize(def);
    LayerDefinition::supportDropout(def);
    LayerDefinition::addInput()
        .setRepeatable(True)
        .addSupport({ InputType::Dense, InputType::SparseInt, InputType::Sparse })
        .addSupportSeqLevel({0, 1, 2})
        .addDoc("FC Layer is fully connected. Blah blah blah...");
  }
  
  static std::vector<LayerOutputDef> getLayerOutputDefinition(const std::vector<LayerOutputDef>& inputs,
  	    LayerConfig& self) {
  	    // self could be modified, for calculating parameter size, etc.
    LayerOutputDef out;
    out.set_size(self.size());
    out.set_type(InputType::Dense);
    out.set_seq_nested_level(inputs[0].seq_nested_level);
    return { out };
  }
};


REGISTER_LAYER(fc, FCLayer);
```

### 配置解析运行流程

配置解析(config parser)的运行流程如下图所示:

![配置解析运行流程](http://api.paddlepaddle.org/graphviz?dot=https://gist.githubusercontent.com/reyoung/0a3d7bfb44e45d61d7bd80b26ca18fbc/raw/4177e2ca56f0410a65338a089cf4e37b9bb87c93/gistfile1.txt)

1. 读取Paddle Core中所有的Layer Def。
1. 根据所有LayerDef生成解析器ConfigParser
	* 如何生成解析器是每个语言自定义的过程
	* 这个过程可以是离线的过程。即先将所有Layer的LayerDef写入到一个文件里，然后其他语言读取这个文件，来生成代码。
	* 这个过程同时也可以是在线的过程。比如对于Python这种动态类型语言，运行时生成函数比较简单，就没必要先生成代码，再生成函数了。
1. 使用ConfigParser，解析用户的配置文件`trainer_config.conf`。
	* 这时，解析器只返回一个调用图，即Layer与Layer之间的调用关系，而不返回真正的`ModelConfig`。
1. 讲这个调用图传递给Paddle Core，生成真正的`ModelConfig`。
	* 对于每一个Layer，顺序执行 `getLayerOutputDefinition`获得这个Layer的输出，传递给下一个Layer。
	* 在C++端真正的生成每一个Layer的LayerConfig，在`getLayerOutputDefinition`中，用户可以对生成的LayerConfig进行修改。例如添加辅助输入，设置参数大小等等。
